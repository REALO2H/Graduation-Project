{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image  level  inverted\n",
      "0   10_left      0     False\n",
      "1  10_right      0     False\n",
      "2   13_left      0     False\n",
      "3  13_right      0     False\n",
      "4   15_left      1     False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "#s\n",
    "\n",
    "\n",
    "labels_df = pd.read_csv('../labels_cleaned.csv') \n",
    "labels_df['inverted'] = False\n",
    "print(labels_df.head())\n",
    "\n",
    "image_dir = '../Images\\\\train\\\\' \n",
    "def load_image(image_name):\n",
    "    file_extension = '.jpeg'\n",
    "    filename = f\"{image_name}{file_extension}\"\n",
    "    file_path = os.path.join(image_dir, filename)\n",
    "    return Image.open(file_path)\n",
    "\n",
    "for i in range (1):\n",
    "    sample_image = load_image(labels_df.iloc[i]['image'])\n",
    "    sample_image.show()\n",
    "\n",
    "\n",
    "# Cleaning the dataset\n",
    "\n",
    "# valid_rows = []\n",
    "# for index, row in labels_df.iterrows():\n",
    "#     image_name = row['image']\n",
    "#     image_path = os.path.join(image_dir, f\"{image_name}.jpeg\")\n",
    "#     if os.path.exists(image_path):\n",
    "#         valid_rows.append(row)\n",
    "\n",
    "# cleaned_df = pd.DataFrame(valid_rows)\n",
    "# cleaned_df.to_csv('labels_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inversion checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_inverted(image):\n",
    "    try:\n",
    "        # Ensure the image is fully loaded\n",
    "        image.load()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image data: {e}\")\n",
    "        raise e  # Re-raise the exception\n",
    "\n",
    "    try:\n",
    "        # Ensure image is in RGB mode\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        # Convert PIL image to OpenCV format\n",
    "        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting image to OpenCV format: {e}\")\n",
    "        raise e  # Re-raise the exception\n",
    "\n",
    "    try:\n",
    "        # Detect features\n",
    "        optic_nerve_pos = detect_optic_nerve(cv_image)\n",
    "        macula_pos = detect_macula(cv_image)\n",
    "        notch_present = detect_notch(cv_image)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature detection: {e}\")\n",
    "        raise e\n",
    "\n",
    "    # Ensure features were detected\n",
    "    if optic_nerve_pos is None or macula_pos is None:\n",
    "        print(\"Could not detect optic nerve or macula.\")\n",
    "        return False  # Or handle as per your needs\n",
    "\n",
    "    # Calculate optic nerve midline (y-coordinate)\n",
    "    optic_nerve_midline_y = optic_nerve_pos['y']\n",
    "\n",
    "    # Compare macula position to optic nerve midline\n",
    "    macula_higher = macula_pos['y'] < optic_nerve_midline_y\n",
    "\n",
    "    # Determine inversion based on criteria\n",
    "    if (macula_higher) or (not notch_present):\n",
    "        # Image is inverted\n",
    "        return True\n",
    "    else:\n",
    "        # Image is not inverted\n",
    "        return False\n",
    "\n",
    "def correct_inversion(image):\n",
    "    # Flip the image vertically\n",
    "    corrected_image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    return corrected_image\n",
    "\n",
    "\n",
    "    #<<functions for feature detection>>\n",
    "\n",
    "    # Optic never detection\n",
    "def detect_optic_nerve(image):\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray_image = image\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "    # Apply thresholding to segment bright areas\n",
    "    _, thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest bright area is the optic nerve\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # Calculate the center of the optic nerve\n",
    "        M = cv2.moments(largest_contour)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10'] / M['m00'])  # x-coordinate\n",
    "            cy = int(M['m01'] / M['m00'])  # y-coordinate\n",
    "            return {'x': cx, 'y': cy}\n",
    "    return None\n",
    "\n",
    "\n",
    "#Macula detection\n",
    "\n",
    "def detect_macula(image):\n",
    "    # Convert to grayscale if necessary\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # green_channel = image[:, :, 1]\n",
    "    else:\n",
    "        gray_image = image\n",
    "        # green_channel = image\n",
    "        \n",
    "\n",
    "    # Image dimensions\n",
    "\n",
    "    height, width = gray_image.shape\n",
    "    # height, width = green_channel.shape\n",
    "\n",
    "    # Define the central region (e.g., central 50% of the image)\n",
    "    x_start = int(width * 0.2)\n",
    "    x_end = int(width * 0.8)\n",
    "    y_start = int(height * 0.2)\n",
    "    y_end = int(height * 0.8)\n",
    "\n",
    "    # Crop the central region\n",
    "    central_region = gray_image[y_start:y_end, x_start:x_end]\n",
    "    # central_region = green_channel[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    #Gaussian Blur \n",
    "    blurred = cv2.GaussianBlur( central_region, (5, 5), 0,cv2.BORDER_DEFAULT)\n",
    "\n",
    "    #Thresholding\n",
    "    res,thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    #Contours\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        print(\"No dark regions detected in the central area.\")\n",
    "        return {'x': 0, 'y': 0}\n",
    "    \n",
    "    # Assume the largest dark contour corresponds to the macula\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Calculate the centroid of the largest contour\n",
    "    M = cv2.moments(largest_contour)\n",
    "    if M['m00'] == 0:\n",
    "        print(\"Zero division error while calculating centroid.\")\n",
    "        return {'x': 0, 'y': 0}\n",
    "\n",
    "    cX = int(M['m10'] / M['m00']) + x_start\n",
    "    cY = int(M['m01'] / M['m00']) + y_start\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create a resizable window\n",
    "    cv2.namedWindow('Grayscale Image', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Grayscale Image', 800, 600)  # Set to desired dimensions\n",
    "    cv2.namedWindow('Blurred Image', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Blurred Image', 800, 600)  \n",
    "    cv2.namedWindow('Thresholded Central Region', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Thresholded Central Region', 800, 600)  \n",
    "    cv2.namedWindow('Detected Macula', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Detected Macula', 800, 600)  \n",
    "    cv2.namedWindow('Central Region', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Central Region', 800, 600)\n",
    "    cv2.namedWindow('res', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Central Region', 800, 600) \n",
    "    cv2.circle(central_region, (cX, cY), 30, (0, 0, 255), -1)  # Red circle for macula\n",
    "    cv2.circle(image, (cX, cY), 30, (0, 0, 255), -1)  # Red circle for macula\n",
    "    cv2.circle(thresh, (cX, cY), 30, (0, 0, 255), -1)  # Red circle for macula\n",
    "   \n",
    "\n",
    "    cv2.imshow('Grayscale Image', gray_image)\n",
    "    # cv2.imshow('Grayscale Image',green_channel)\n",
    "    cv2.imshow('Blurred Image', blurred)\n",
    "    cv2.imshow('Thresholded Central Region', thresh)\n",
    "    cv2.imshow('res', res)\n",
    "    cv2.imshow('Detected Macula', image)\n",
    "    cv2.imshow('Central Region', central_region)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    return {'x': cX, 'y': cY}\n",
    "\n",
    "#Notch detection\n",
    "def detect_notch(image):\n",
    "    # Convert to grayscale if necessary\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray_image = image\n",
    "\n",
    "    # Crop the edges of the image where the notch is expected\n",
    "    height, width = gray_image.shape\n",
    "    edge_width = int(width * 0.05)  # Adjust as needed\n",
    "\n",
    "    # Left edge\n",
    "    left_edge = gray_image[:, :edge_width]\n",
    "    # Right edge\n",
    "    right_edge = gray_image[:, -edge_width:]\n",
    "\n",
    "    # Combine edges\n",
    "    edges = [left_edge, right_edge]\n",
    "\n",
    "    # Look for contours in the edge regions\n",
    "    for edge in edges:\n",
    "        # Apply thresholding\n",
    "        _, thresh = cv2.threshold(edge, 35, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Analyze contours\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 100:  # Adjust threshold based on expected notch size\n",
    "                # Approximate contour to a polygon\n",
    "                approx = cv2.approxPolyDP(cnt, 0.04 * cv2.arcLength(cnt, True), True)\n",
    "                # Check for square, triangle, or circle\n",
    "                if len(approx) == 3 or len(approx) == 4 or len(approx) > 8:\n",
    "                    return True  # Notch detected\n",
    "    return False  # No notch detected \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 10_left\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for index, row in labels_df.iterrows():\n",
    "    image_name = row['image']\n",
    "    print(f\"Processing image {image_name}\")\n",
    "    image = load_image(image_name)\n",
    "\n",
    "    if image is not None:\n",
    "        try:\n",
    "            inverted = is_inverted(image)\n",
    "            labels_df.at[index, 'inverted'] = inverted\n",
    "            print(f\"Image {image_name} inverted: {inverted}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_name}: {e}\")\n",
    "            labels_df.at[index, 'inverted'] = None\n",
    "    else:\n",
    "        print(f\"Skipping image {image_name} due to loading error.\")\n",
    "        labels_df.at[index, 'inverted'] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test on a sample image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sample_image \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m(labels_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m8\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m cv_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(np\u001b[38;5;241m.\u001b[39marray(sample_image), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Detect features\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_image' is not defined"
     ]
    }
   ],
   "source": [
    "# Test on a sample image\n",
    "sample_image = load_image(labels_df.iloc[8]['image'])\n",
    "cv_image = cv2.cvtColor(np.array(sample_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Detect features\n",
    "optic_nerve_pos = detect_optic_nerve(cv_image)\n",
    "macula_pos = detect_macula(cv_image)\n",
    "notch_present = detect_notch(cv_image)\n",
    "\n",
    "print(f\"Optic Nerve Position: {optic_nerve_pos}\")\n",
    "print(f\"Macula Position: {macula_pos}\")\n",
    "print(f\"Notch Present: {notch_present}\")\n",
    "\n",
    "# Display the image with detected points\n",
    "if optic_nerve_pos and macula_pos:\n",
    "    cv2.circle(cv_image, (optic_nerve_pos['x'], optic_nerve_pos['y']), 50, (0, 255, 0), -1)\n",
    "    cv2.circle(cv_image, (macula_pos['x'], macula_pos['y']), 50, (0, 0, 255), -1)\n",
    "\n",
    "     # Create a resizable window\n",
    "    cv2.namedWindow('Detected Features', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Detected Features', 800, 600)  # Set to desired dimensions\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    cv2.imshow('Detected Features', cv_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
